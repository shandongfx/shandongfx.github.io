---
title: "Work with GIS data in R"
layout: default
---
## Work with GIS data in R  
*The ducoment is based on the workshop I tought on Oct. 25 2015, Interdepartmental Workshop Series, Oklahoma State University, Stillwater, OK*

## 1. basic
Install and load libraries.

```{r,echo=TRUE,message=FALSE}

# install.packages("rgdal") 
# install.packages("raster")
# install.packages("dismo")
library("rgdal") # this package is the basis of analyzing GIS data in R; for example, it handle basis coordinate systems, it defines a lot of spatial data types
library("raster")
library("dismo")

```

## 2. warm up 
R is pretty fun to use, let's plot some maps from one line of code
```{r,fig.keep = 'last',message=FALSE}
require("XML")
# get a map of OK, you could type text that used to search on Google Maps
myMap <- gmap("oklahoma")
raster::plot(myMap)
```
```{r,fig.keep = 'last'}
# try different text
plot(gmap("stillwater,OK")) # seems good
```
```{r,fig.keep = 'last'}
# get a snapshot of Walmart (satellite image)
plot(gmap("walmart,stillwater,OK",type = "satellite") )
```
```{r,fig.keep = 'last'}
# get a snapshot of Boomer Lake (satellite image)
plot(gmap("boomer lake,stillwater,OK",type = "satellite") )
```

## 3. spatial points
### 3.1 generate spatial points

```{r,fig.keep = 'last'}
# get a map of OK 
myMap <- gmap("Oklahoma",lonlat=TRUE)
```

```{r}
# show the extent of this map (raster)
okExtent<- extent(myMap)
okExtent
```

```{r}
# generate 10 random points (longitude & latitude) within this extent
myLongitude <- runif(n=10, min=okExtent[1] ,max=okExtent[2] )
myLatitude <- runif(n=10, min=okExtent[3] ,max=okExtent[4] )

# combine longitude and latitude by column
coords <- cbind(myLongitude,myLatitude)
head(coords)
```

```{r}
# make the points spatial
myPoints <- SpatialPoints(coords)

# plot the points
plot(myPoints) # but there is no background
```

```{r,fig.keep='last'}
# add some background
plot(myMap)
plot(myPoints, add=TRUE, col="red")
```


### 3.2 generate spatial points with attribute column

```{r}
# generate random attribute for the points
myAtt <- sample(c("presence","absence"),10,replace=TRUE)

# change myAtt to DataFrame
myAtt <- as.data.frame(myAtt)
head(myAtt)

# make spatial data frame (spatial points with attributes)
myPoints <- SpatialPointsDataFrame(coords,as.data.frame(myAtt))

# show the attribute of myPoints
myPoints@data

```



### 3.3 select a subset of points based on attributes
```{r}
# This is like subsetting a dataframe
myPoints_presence <- myPoints[myPoints$myAtt=="presence", ]

# plot the previously selected points as red
plot(myPoints)
plot(myPoints_presence,add=T,col="red")

```

### 3.4 save our selected file as a shape file
```{r}
# the 1st parameter is the object, the 2nd parameter is the path and file name
shapefile(myPoints_presence,filename="temp/output.shp",overwrite=TRUE)
#file.exists("output.shp")
```

## 4. spatial polygons

### 4.1 build buffer of points, the unit of width depends on the geographic reference system of "myPoints"
```{r}
# build a dissolved buffer
myBuffer <- buffer(myPoints,width=1)
length(myBuffer)
plot(myBuffer)


# build buffer independently for each point
myBuffer <- buffer(myPoints,width=1,dissolve=FALSE)
length(myBuffer)
plot(myBuffer)

# plot them
plot(myMap)
plot(myPoints,add=T)
plot(myBuffer,add=T)
```



### 4.2 load existing polygons (data from <http://www.diva-gis.org/Data>)
```{r}
# use the shapefile function, which is used for export if the object is specified
map_state <- shapefile("data/USA_adm1.shp")

# show the summary of the data
summary(map_state)

# show the structure of the data
head(map_state@data, n=5)

# show one colume
map_state$NAME_1

# plot the data
plot(map_state)
```


### 4.3 subset
```{r}
# only select Oklahoma
map_ok <- map_state[map_state$NAME_1 == "Oklahoma", ]
plot(map_ok)

# select states large area (> 30)
# step 1: do the logic judgement
selection <- map_state$Shape_Area > 30
# step 2: subset
map_selected <- map_state[selection,]

# the following code shows the same results, but I will nor run it.
#map_selected <- map_state[map_state$Shape_Area < 10,]

# show all columns/fields/attributes of the selections
map_selected@data
plot(map_selected)
```

### 4.4 save polygons
```{r}
shapefile(map_selected,"temp/selected_states.shp",overwrite=TRUE)

```


## 5. spatial raster

### 5.1 read/write raster files (data from <http://www.worldclim.org>)
```{r}
# read one raster layer
myLayer<- raster("data/bio1.bil")
plot(myLayer)
# write one raster layer (not run)
# writeRaster(myLayer,filename="temp/ok_bio1.bil",format="EHdr",overwrite=TRUE)

# load several raster layers
# step 1 get a list of file names
list.files("data/") # we need to filter the names
list.files("data/",pattern=".bil") # the names are correct, but we need the full path
list.files("data/",pattern=".bil", full.names = TRUE) # the full name give you a relative path to current working directory
myFiles <- list.files("data/",pattern=".bil", full.names = TRUE) 

# step 2 treat them as raster stack
myLayers <- stack(myFiles)
plot(myLayers)

# save several raster layers
formattedNames <- paste("temp/",names(myLayers),".bil", sep="")
formattedNames
# not run
# writeRaster(myLayers,filename= formattedNames, format="EHdr", bylayer=TRUE)
```

### 5.2 extraction by polygon
```{r}
# we only want to show Oklahoma, extract raster layer by polygon
raster_ok <- mask(myLayer, map_ok) # we may get error if the reference systems are different
```

### 5.3 projection
```{r}
# check their CRS
crs(myLayer)
crs(map_ok)

# unify the CRS
map_ok_new <- spTransform(map_ok, crs(myLayer))
crs(map_ok_new)

# extract raster by polygon 
raster_ok <- crop( myLayer ,extent(map_ok_new) ) # first cut by a rectangle
raster_ok <- mask(raster_ok, map_ok_new) # then cut by boundary
plot(raster_ok)

```

### 5.4 extract by point
```{r}
extract(raster_ok,myPoints)
```

### 5.5 resample
```{r}
# we want the new layer to be 3 times coarser at each axis (9 times coarser)
# read current resolution
raster_ok
nrow(raster_ok)
ncol(raster_ok)
extent(raster_ok)

# define new resolution
newRaster <- raster( nrow= nrow(raster_ok)/3 , ncol= ncol(raster_ok)/3 )

# define extent
extent(newRaster) <- extent(raster_ok)

# fill the new layer with new values
newRaster <- resample(x=raster_ok,y=newRaster,method='bilinear')
plot(newRaster) # new layer seems coarser
```

### 5.6 reclassify raster layer
```{r}
# we want to classify the world into two classes based on temperature, high > mean & low < mean
myLayer<- raster("data/bio1.bil")

# values smaller than meanT becomes 1; values larger than meanT will be 2
myMethod <- c(-Inf, 100, 1,  100, Inf, 2)
myLayer_classified <- reclassify(myLayer,rcl= myMethod)
plot(myLayer_classified)
```

### 5.7 raster calculation
```{r}
# read precipitation data 
wet <- raster("data/bio13.bil") # precipitation of wettest month
dry <- raster("data/bio14.bil") # precipitation of driest month
plot(stack(wet,dry))

# calculate the difference
diff <- wet - dry
#plot(diff)

# calculate the mean of the two month
twoLayers <- stack(wet,dry)
meanPPT <- calc(twoLayers,fun=mean)
#plot(meanPPT)

# the following code gives the same results
meanPPT2 <-  (wet + dry)/2

# histogram of one layer
hist(twoLayers[[1]])

# correlation between different layers
pairs(twoLayers[[1:2]])

```

################################





## references
1. Spatial data in R: Using R as a GIS <http://pakillo.github.io/R-GIS-tutorial/>
